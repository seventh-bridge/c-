# 基于ASIO库的分布式即时通讯项目
## 项目描述
这是一个基于ASIO库的分布式即时通讯项目，提供好友通讯、添加好友等功能。后端采用分布式设计，主要分为四种服务，即网关服务、聊天服务、状态服务和验证服务。各个服务之间通过grpc通信，支持断线重连。网关服务对外采用http服务，和验证服务一同负责处理用户的登录和注册功能。通过状态服务可查询服务器的空闲状况，以实现负载均衡。聊天服务采用asio库实现tcp可靠长连接异步通信和转发，并采用多线程模式封装io_context池来提升并发性能。数据存储则采用mysql服务，并基于mysql connector库封装连接池，同时也封装了redis连接池处理缓存数据，以及grpc连接池保证多服务并发访问。经测试，单服务器可支持7000~8000连接。
## 技术栈
asio网络库，grpc，多线程，MySql，Redis，网络编程
## 项目意义
通过分布式设计， 可以显著缓解高并发场景下对服务器性能的需求，有效提升服务器的服务能力。
## 考察点
1. 如何利用asio库实现tcp服务？
答：利用asio的多线程模式，根据cpu核数创建相应数量的io_context连接池，分配给相应的独立线程，采用异步async_read和async_write来读写，通过消息回调来完成数据收发，使用的网络模式是Proactor模式。使用Session类对连接进行管理，底层将用户id与Session绑定，利用智能指针保证Session类在回调之前都可用，这样回调函数可以通过Session反向查询用户进行消息推送。客户端和服务器之间通信采用json格式，考虑到是tcp，所以使用tlv方式，即消息头+消息内容来封装消息包防止沾包。通过心跳机制检测连接的可用性，即客户端每隔一定时间会向服务器发送一个数据包，表示自己在线。
2. 如何保证服务高可用？
答：
1.采用分布式架构，将应用拆分为多个独立的服务，降低单个服务故障对整体的影响
2.设置监控系统，实时检测服务的可用性。
3.定期备份数据，进行持久化，确保数据丢失或损坏时能够快速恢复。
3. 为什么要封装MySql连接池？
答：因为多个线程使用同一个MySql连接是不安全的，需要给每个线程分配独立连接，但连接数是有限的，因此封装一个连接池，根据连接池的使用情况和任务队列给线程分配连接。
4. MySql连接池怎么封装的？
答：MySql连接池封装了一个管理层和一个数据访问层，其中管理层是单例模式，作为对外接口，数据访问层实现数据访问操作，采用生产者消费者管理可用连接，并通过心跳机制确保连接的可用性。
5. 描述线程池封装
答：整体来说，线程池通过单例封装，内部根据cpu核数初始化相应数量的线程，采用生产者消费者方式管理线程，包含任务队列，提供对外接口commit提交任务，采用bind语法实现任务提交在commit内部绑定，并通过智能指针保证任务生命周期，同时使用C++11的future特性，允许外部等待任务执行完成。
6. 如何测试性能
答：分为两个方面，一是压力测试，测试服务器性能，客户端初始化多个线程定时连接，直至出现掉线情况；二是稳定性测试，在单服务节点连接数到达一定数量后是否收发稳定，延迟是否在10ms以下，未出现丢包和断线等问题。测试方法：采用pingpong协议。
7. 为什么要设计心跳机制
答：因为客户端可能突然崩溃，但服务器未检测到其已经断开连接，则其会成为僵尸连接，会造成服务器性能的损耗。此外，对MySql、Redis来说，若长时间不访问，则其会自动断开连接，心跳机制可以保证连接的持续可用性。

## 1.关于IO_CONTEXT池的设计
1. 根据CPU核数创建io_context池，这是常见的1:1线程模型。在实际测试中，你是否发现这种模型在某些场景下（比如I/O密集型但计算不密集时）可能不是最优的？考虑过使用N:M模型吗？
答：在I/O密集的场景下，它的性能主要由I/O操作的延迟来决定，不过在这种情况下，采用N：M模型来创建io_context池，可以更快地响应请求，减少潜在的I/O阻塞，从而提升并发能力。一般来说，具体数值需要通过实际的性能测试和系统负载分析来决定。
2. 对于io_context的分配策略，是采用全局队列还是线程本地存储？当某个io_context负载过高时，是否有动态调整的机制？
答：如果在任务负载均匀分布的情况下，可以采用全局队列，而在任务负载不均匀的情况下，则应该采用线程本地存储，即每个线程都有自己的局部队列。而当某个io_context负载过高时，可以通过线程池的拓展增加处理线程的数量来分担任务，或者迁移任务给相对空闲的io_context，也可以暂时停止向任务队列中增加任务，即拒绝请求。
3. 项目中使用了多线程模式封装io_context池，请问你是如何设计线程与io_context的绑定关系的？为什么选择这种设计而不是其他方案？
答：这个项目采用的是一个线程绑定一个io_context的模式。采用这种模式是因为它可以充分发挥多核的优势，且socket描述符不会在多个线程之间共享，不需要引入同步机制。
4. 新连接是随机分配到io_context还是采用最少连接分配？当需要动态调整连接分布时如何实现？
答：采用最少连接分配，这样是为了避免某个线程负载过多。此外，设置实时监控连接负载，当某个io_context的负载超过某个阈值时，会将连接分配给负载较低的io_context。
5. 多线程模式为什么不用多个线程共享一个io_context模式？
答：这种模式有一个隐患，同一个socket触发的回调函数可能在不同的线程，若触发间隔时间很小，那么可能会出现不同线程并发访问数据的情况，造成数据混乱。
6. 考虑过让空闲线程从其他io_context的任务队列"窃取"任务吗？这种方案的复杂度与收益如何权衡？
答：考虑过，从其他io_context的任务队列中窃取任务的实现复杂度较高，需要在任务队列之间进行同步操作，通常会用锁、原子操作等机制来确保线程之间的安全访问，增加额外开销。如果有大量的并发任务，且负载不均匀时，采用这种方式可以有效提升性能。

## 2.关于异步通信实现
1. 你使用了async_read/async_write，对于消息的连续性处理，是如何保证一个完整消息（头+内容）被完整接收后才触发回调的？特别是在网络波动时如何处理部分接收的情况？
答：因为消息头中包含了消息ID和消息长度，每次处理接收的数据时，先看收到的数据头部长度是否大于设定的长度，若大于则接收到了此次消息ID和消息长度，然后看当前接收的消息内容长度小于消息头中的消息长度，则表示未完整接收。而在网络波动时，会存在部分接收的情况，此时消息ID可以确认消息发送的顺序，如果某些消息丢失，接收方可以请求重新发送。
2. 在Proactor模式下，回调函数中如果进行耗时操作（比如数据库访问），是否会阻塞事件循环？你是如何解决这个问题的？
答：若回调函数中执行耗时操作，可能会导致回调函数本身阻塞。因此，对于数据的读写，我采用的是async_read和async_write的异步读写操作。

## 3.关于消息协议设计
1. 选择JSON作为通信格式是出于什么考虑？在性能测试中是否发现JSON的解析/序列化成为瓶颈？考虑过其他二进制协议如Protobuf吗？
答：选择JSON作为通信格式，一是考虑到JSON的易读性和调试方便，二是JSON受广泛支持，大多数编程语言和框架都支持JSON格式。在数据量比较大的情况下，JSON的解析/序列化会需要占用大量的内存，可能会影响性能。而Protobuf相对于JSON来说，二进制格式更加紧凑，占用的网络带宽较少，同时序列化和反序列化更快，不过它是二进制格式，可读性较差，复杂度比较高。

## 4.性能优化方面
1. 当单个连接的消息速率非常高时（比如每秒上千条消息），你的架构如何保证不会因为某个连接而影响其他连接的公平性？
答：采用分布式架构，可以将负载分散到多个服务上，这样可以确保在某个连接的消息速率很高的情况下，其他连接也可以正常处理。

## 5.错误处理
1. 当async_write失败时（比如连接断开），你是如何清理相关资源的？如何保证不会出现资源泄漏？
答：当async_write失败时，函数会返回相应的错误码，表示连接断开、超时或网络不可用等错误类型，那么就根据错误码来清理相关资源，例如连接断开导致的失败，则关闭连接、销毁相关对象。此外，采用智能指针来确保资源不再使用时自动释放。
2. 在网络闪断的情况下，重连机制是如何与消息队列配合工作的？如何保证重连后不会丢失关键消息？
答：消息队列提供持久化功能，在发送到队列之前，会被存储在磁盘中，直到被消费。

## 6.测试
1. 每个线程的栈空间是如何配置的？在大量线程情况下如何避免内存浪费？
答：使用线程池来复用线程，避免频繁地创建和销毁线程，这样就不会随着线程数量的增加而过多地消耗内存

## 7.MySql、Redis
1. 封装Mysql、redis连接池时，如何确定最大连接数、空闲连接超时等参数？
答：最大连接数主要是根据并发请求量和数据库的承载能力来设置，在高并发场景下，连接数可以适当设置较大的值，这里设置的是200。最大空闲连接超时设置的是5分钟。

## 8.grpc
1. 项目中采用了四种微服务，你如何保证服务间GRPC通信的可靠性和性能？特别是在断线重连的情况下如何保证消息不丢失？
答：grpc本身支持自动重连机制，其次是设计消息确认机制，即在发送端返回的响应中加入消息的处理状态，接收端确认收到并处理完消息后再进行下一步操作。